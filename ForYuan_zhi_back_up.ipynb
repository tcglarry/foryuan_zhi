{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ForYuan_zhi_back_up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcglarry/foryuan_zhi/blob/master/ForYuan_zhi_back_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pdFPSPcb-mO-",
        "outputId": "a731f917-0fd4-44fe-aff1-964fd1278441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"ali_build_model_fit_generator_cat11_xgb_confuse_testing.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1eTvR6DsVXG_usdQ-5GSz0hPBI_ysspxB\n",
        "\"\"\"\n",
        "\n",
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 22280 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.0-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FvN43omF1HPC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# connect google drive\n",
        "## be reminded to have a folder: yzu with 3 files inside\n",
        "1. diabetes.csv\n",
        "2. X.npy\n",
        "3. y.npy"
      ]
    },
    {
      "metadata": {
        "id": "vS1gO7N3x7Qb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "6aa9ca22-7719-4a4e-ff25-fce88a5216dd"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S04c-JHnzBx-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dfef5e5-7b79-465f-d192-1fc340173825"
      },
      "cell_type": "code",
      "source": [
        "!ls 'drive/My Drive/yzu'\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "diabetes.csv  X.npy  Y.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "V6yrwwhT_cwN"
      },
      "cell_type": "markdown",
      "source": [
        "# Example: PIMA Diabetes"
      ]
    },
    {
      "metadata": {
        "id": "MdtNDnQ40hlz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2GZ5HhLV_XhV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First XGBoost model for Pima Indians dataset\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "# load data\n",
        "src = 'drive/My Drive/yzu/'\n",
        "dataset = pd.read_csv(src+'diabetes.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJASw9lnx7Qk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "1c0b8cb6-8cd6-4854-dbb7-5176e881296f"
      },
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
              "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
              "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
              "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
              "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
              "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
              "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
              "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
              "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
              "\n",
              "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
              "count  768.000000                768.000000  768.000000  768.000000  \n",
              "mean    31.992578                  0.471876   33.240885    0.348958  \n",
              "std      7.884160                  0.331329   11.760232    0.476951  \n",
              "min      0.000000                  0.078000   21.000000    0.000000  \n",
              "25%     27.300000                  0.243750   24.000000    0.000000  \n",
              "50%     32.000000                  0.372500   29.000000    0.000000  \n",
              "75%     36.600000                  0.626250   41.000000    1.000000  \n",
              "max     67.100000                  2.420000   81.000000    1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jr5RZlH6AF4g",
        "outputId": "f3328f8b-57fe-495c-8bae-659e20cdbbf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "77Ltm4jMAc0g",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_set = dataset.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4lLFyo_b-_f2",
        "outputId": "48d9a193-3f68-42b7-a65f-2e66b8ea93ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "# split data into X and y\n",
        "X = data_set[:,0:8]\n",
        "Y = data_set[:,8]\n",
        "# split data into train and test sets\n",
        "seed = 7\n",
        "test_size = 0.33\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "# fit model no training data\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 77.95%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jZhsAiLjFqsu",
        "outputId": "07e47a3d-cd5d-4712-9333-0d3e8f8e8a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "print (classification_report(y_test,predictions))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.84      0.83       162\n",
            "        1.0       0.70      0.67      0.69        92\n",
            "\n",
            "avg / total       0.78      0.78      0.78       254\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pL2QsGN10XDU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Change Thrshold"
      ]
    },
    {
      "metadata": {
        "id": "a_ol50XEx7RC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4e3df9f-44ea-4ec2-f868-8dc8ae53295f"
      },
      "cell_type": "code",
      "source": [
        "predictions_03 = model.predict_proba(X_test)[:,1] > 0.3\n",
        "accuracy = accuracy_score(y_test, predictions_03)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 73.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8xANFnFXVcDV",
        "outputId": "9ed23984-3931-4c73-9657-094b7749a9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print (classification_report(y_test,predictions_03))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.69      0.77       162\n",
            "        1.0       0.60      0.82      0.69        92\n",
            "\n",
            "avg / total       0.77      0.73      0.74       254\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MqMOXe2vV22R",
        "outputId": "d1acf964-eeed-430e-f31a-8d66cb053bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "print (classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.69      0.77       162\n",
            "        1.0       0.60      0.82      0.69        92\n",
            "\n",
            "avg / total       0.77      0.73      0.74       254\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5R0ZrNfDF6H2",
        "outputId": "13b30ae9-389d-485c-9fa6-fbc1fc12ec5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "gbc =  SVC()\n",
        "gbc.fit(X_train,y_train)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "  tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0pGU2mU2Gyyr",
        "outputId": "3c5feb3f-6cf4-4d16-8ff3-7a6feece19b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = gbc.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 63.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9Zq6y4AXG9KI",
        "outputId": "9c041aca-15a4-4c26-b4fa-fe14bee1e20b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "print (classification_report(y_test,predictions))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.64      1.00      0.78       162\n",
            "        1.0       0.00      0.00      0.00        92\n",
            "\n",
            "avg / total       0.41      0.64      0.50       254\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qpoUF0BHJkon",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zV1-ei9X0-eG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Example Hand Signal "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Gu38S3UZJk0K",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GuWR3r2uJk6N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aaBOl_eoJlKN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "657739a1-4482-40fa-db8f-9591c526ff99"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.preprocessing import image\n",
        "#from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator,  img_to_array, load_img\n",
        "\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import subprocess\n",
        "import os\n",
        "import pickle\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, merge, Lambda,UpSampling2D, concatenate, Reshape, Dropout,Cropping2D,Activation\n",
        "from keras.models import Model, load_model\n",
        "import pandas as pd\n",
        "import sklearn \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.nasnet import NASNetMobile,NASNetLarge\n",
        "import matplotlib.image as mpimg\n",
        "from skimage import io\n",
        "from xgboost.sklearn import XGBClassifier"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "u0TFN8q2x7Rv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fee5343-7660-44b0-9760-80bb2aa671a2"
      },
      "cell_type": "code",
      "source": [
        "X= np.load(src+'X.npy')\n",
        "X.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2062, 64, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "__4jj6nV1qf7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# take a look:  random sleect a picture (eg. picture number 200)"
      ]
    },
    {
      "metadata": {
        "id": "YE-UT9JNx7R1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "7daea73c-b7e9-4999-82ec-104f53f03137"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X[200,:,:],cmap='gray')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f96ba237b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFMCAYAAABCsp4mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2DPXAdCPnPIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f96ba27b668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1jFhf3OQHSk5",
        "outputId": "4e4b898f-43c4-41c1-8301-7f6a1b49581c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "y =  np.load(src+'Y.npy')\n",
        "y.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2062, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ri1SU2EgYHNK",
        "outputId": "f2fa0a6a-ea55-43b0-f182-1802c840aede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "y[-5:,:]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kL8ceLhMITkR",
        "outputId": "63c65a78-18d3-4a3b-cae6-3d242d5598cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "X= X[:,:,:,np.newaxis]\n",
        "X.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2062, 64, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fPHyvzV5Z4iq",
        "outputId": "9f9b480f-03c2-4578-f921-6a3f6ebacd67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.concatenate([X,X,X],axis=-1)\n",
        "X.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2062, 64, 64, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PrkiCbY9LqY9",
        "outputId": "705853ac-8eac-4fd3-84e7-56baa2601edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
        "print (X_train.shape)\n",
        "print (X_test.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1443, 64, 64, 3)\n",
            "(619, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jefe3Ae3JFtL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def conv_block(ch, activation= 'relu', padding='same',kernel_regularizer=regularizers.l2(0.01)):       \n",
        "    return Conv2D(ch,(3,3),activation= activation, padding =padding )\n",
        "\n",
        "\n",
        "def build_model(ch=32):\n",
        "    #inputs = Input((IMAGE_HEIGHT,IMAGE_WIDTH,ch))\n",
        "    inputs = Input((64,64,1))\n",
        "\n",
        "    x = Conv2D(32,(2,2),padding='valid')(inputs)\n",
        " \n",
        "    x =  conv_block(ch)(x)\n",
        "    x = conv_block(ch)(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "    \n",
        "    x =  conv_block(ch*2)(x)\n",
        "    x = conv_block(ch*2)(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "    \n",
        "    x =  conv_block(ch*4)(x)\n",
        "    x = conv_block(ch*4)(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "    \n",
        "    x =  conv_block(ch*8)(x)\n",
        "    x = conv_block(ch*8)(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "    \n",
        "    x= GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    x = Dense (128, activation = 'relu' )(x)\n",
        "    \n",
        "    x = Dense (32, activation = 'relu' )(x)\n",
        "    \n",
        "    output = Dense(10,activation = 'softmax')(x)\n",
        "    \n",
        "    model = Model(inputs= inputs, outputs=output)\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iKR2VHWZYo7n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model_2():\n",
        "    inputs = Input(shape=(64,64,3))\n",
        "    #inputs = Lambda(lambda x: x/275. - 1.0)(inputs)\n",
        "    # create the base pre-trained model\n",
        "    base_model = DenseNet121(weights='imagenet',input_tensor=inputs,  include_top=True)\n",
        "    \n",
        "    x = base_model.layers[-2].output\n",
        "    \n",
        "    x = Dense(128,activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    x = Dense(32,activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    output = Dense(10,activation = 'softmax')(x)\n",
        "    \n",
        " \n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F1AIqvzu3x48",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# del model    del model only if you want to restart learning "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LBZsX-rLK4CH",
        "outputId": "ad8f116a-34e2-4631-ce4d-e0774ca61263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16567
        }
      },
      "cell_type": "code",
      "source": [
        "model = build_model_2()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 70, 70, 3)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 32, 32, 64)   9408        zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 32, 32, 64)   0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 34, 34, 64)   0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 16, 16, 64)   0           zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 16, 16, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 16, 16, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 16, 16, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 16, 16, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 16, 16, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 16, 16, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 16, 16, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 16, 16, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 16, 16, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 16, 16, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 16, 16, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 16, 16, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 16, 16, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 16, 16, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 16, 16, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 16, 16, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 16, 16, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 16, 16, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 16, 16, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 16, 16, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 16, 16, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 16, 16, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 16, 16, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 16, 16, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 16, 16, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 16, 16, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 16, 16, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 16, 16, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 16, 16, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 8, 8, 128)    0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 8, 8, 128)    512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 8, 8, 128)    0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 8, 8, 160)    0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 8, 8, 160)    640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 8, 8, 160)    0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 8, 8, 192)    0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 8, 8, 192)    768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 8, 8, 192)    0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 8, 8, 224)    0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 8, 8, 224)    896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 8, 8, 224)    0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 8, 8, 256)    0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 8, 8, 256)    0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 8, 8, 128)    0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 8, 8, 288)    0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 8, 8, 288)    1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 8, 8, 288)    0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 8, 8, 128)    36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 8, 8, 128)    0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 8, 8, 320)    0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 8, 8, 320)    1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 8, 8, 320)    0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 8, 8, 128)    40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 8, 8, 128)    0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 8, 8, 352)    0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 8, 8, 352)    1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 8, 8, 352)    0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 8, 8, 128)    45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 8, 8, 128)    0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 8, 8, 384)    0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 8, 8, 384)    1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 8, 8, 384)    0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 8, 8, 128)    49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 8, 8, 128)    0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 8, 8, 416)    0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 8, 8, 416)    1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 8, 8, 416)    0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 8, 8, 128)    53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 8, 8, 448)    0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 8, 8, 448)    1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 8, 8, 448)    0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 8, 8, 128)    57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 8, 8, 480)    0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 8, 8, 480)    1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 8, 8, 480)    0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 8, 8, 128)    61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 8, 8, 512)    0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 8, 8, 512)    2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 8, 8, 512)    0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 8, 8, 256)    131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 4, 4, 256)    0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 4, 4, 256)    1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 4, 4, 256)    0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 4, 4, 128)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 4, 4, 288)    0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 4, 4, 288)    1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 4, 4, 288)    0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 128)    36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 4, 4, 128)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 4, 4, 320)    0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 4, 4, 320)    1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 4, 4, 320)    0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 128)    40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 4, 4, 128)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 4, 4, 352)    0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 4, 4, 352)    1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 4, 4, 352)    0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 128)    45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 4, 4, 128)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 4, 4, 384)    0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 4, 4, 384)    1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 4, 4, 384)    0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 128)    49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 4, 4, 128)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 4, 4, 416)    0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 4, 4, 416)    1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 4, 4, 416)    0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 128)    53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 4, 4, 128)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 4, 4, 448)    0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 4, 4, 448)    1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 4, 4, 448)    0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 4, 4, 128)    57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 4, 4, 128)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 4, 4, 480)    0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 4, 4, 480)    1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 4, 4, 480)    0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 4, 4, 128)    61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 4, 4, 128)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 4, 4, 512)    0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 4, 4, 512)    0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 4, 4, 128)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 4, 4, 544)    0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 4, 4, 544)    2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 4, 4, 544)    0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 4, 4, 128)    69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 4, 4, 576)    0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 4, 4, 576)    2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 4, 4, 576)    0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 4, 4, 128)    73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 4, 4, 608)    0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 4, 4, 608)    2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 4, 4, 608)    0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 4, 4, 128)    77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 4, 4, 640)    0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 4, 4, 640)    2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 4, 4, 640)    0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 4, 4, 128)    81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 4, 4, 672)    0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 4, 4, 672)    2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 4, 4, 672)    0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 4, 4, 128)    86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 4, 4, 704)    0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 4, 4, 704)    2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 4, 4, 704)    0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 4, 4, 128)    90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 4, 4, 736)    0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 4, 4, 736)    2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 4, 4, 736)    0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 4, 4, 128)    94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 4, 4, 768)    0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 4, 4, 768)    3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 4, 4, 768)    0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 4, 4, 128)    98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 4, 4, 800)    0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 4, 4, 800)    3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 4, 4, 800)    0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 4, 4, 128)    102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 4, 4, 832)    0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 4, 4, 832)    3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 4, 4, 832)    0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 4, 4, 128)    106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 4, 4, 864)    0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 4, 4, 864)    3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 4, 4, 864)    0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 4, 4, 128)    110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 4, 4, 896)    0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 4, 4, 896)    3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 4, 4, 896)    0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 4, 4, 128)    114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 4, 4, 928)    0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 4, 4, 928)    0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 4, 4, 960)    0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 4, 4, 960)    0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 4, 4, 992)    0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 4, 4, 992)    0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 4, 4, 128)    512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 4, 4, 128)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 4, 4, 1024)   0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 4, 4, 1024)   4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 4, 4, 1024)   0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 4, 4, 512)    524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 2, 2, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 2, 2, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 2, 2, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 2, 2, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 2, 2, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 2, 2, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 2, 2, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 2, 2, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 2, 2, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 2, 2, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 2, 2, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 2, 2, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 2, 2, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 2, 2, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 2, 2, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 2, 2, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 2, 2, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 2, 2, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 2, 2, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 2, 2, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 2, 2, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 2, 2, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 2, 2, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 2, 2, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 2, 2, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 2, 2, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 2, 2, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 2, 2, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 2, 2, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 2, 2, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 2, 2, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 2, 2, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 2, 2, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 2, 2, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 2, 2, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 2, 2, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 2, 2, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 2, 2, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 2, 2, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 2, 2, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 2, 2, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 2, 2, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 2, 2, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 2, 2, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 2, 2, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 2, 2, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 2, 2, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 2, 2, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 2, 2, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 2, 2, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 2, 2, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 2, 2, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 2, 2, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 2, 2, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 2, 2, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 2, 2, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 2, 2, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 2, 2, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 2, 2, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 2, 2, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 2, 2, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 2, 2, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 2, 2, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 2, 2, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 2, 2, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 2, 2, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 2, 2, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 2, 2, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 2, 2, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 2, 2, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 2, 2, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 2, 2, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 2, 2, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 2, 2, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 2, 2, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 2, 2, 1024)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          131200      avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 32)           4128        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 10)           330         dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 7,173,162\n",
            "Trainable params: 7,089,514\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-lSZzLjQM1IA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile (optimizer='Adam', loss = ['categorical_crossentropy'], metrics =['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2W-jZ8JU6RT8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model  training with early stops"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fMez_iV_K9zJ",
        "outputId": "dd21f17a-60fe-4832-aed6-e427473075c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2043
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint = ModelCheckpoint(filepath= src+'hand_signal_back_up.h5', monitor = 'val_loss', save_best_only=True, mode= 'auto')\n",
        "earlystop = EarlyStopping(patience=10)\n",
        "callback_list = [checkpoint, earlystop]\n",
        "model.fit(x=X_train, y=y_train, batch_size=32, epochs=300, callbacks = callback_list, verbose=1, validation_split=0.2,  shuffle=True)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1154 samples, validate on 289 samples\n",
            "Epoch 1/300\n",
            "1154/1154 [==============================] - 40s 34ms/step - loss: 1.5665 - acc: 0.4532 - val_loss: 0.6664 - val_acc: 0.8062\n",
            "Epoch 2/300\n",
            "1154/1154 [==============================] - 12s 10ms/step - loss: 0.6458 - acc: 0.8085 - val_loss: 0.7292 - val_acc: 0.8304\n",
            "Epoch 3/300\n",
            "1154/1154 [==============================] - 12s 10ms/step - loss: 0.4027 - acc: 0.8821 - val_loss: 1.8577 - val_acc: 0.7474\n",
            "Epoch 4/300\n",
            "1154/1154 [==============================] - 12s 10ms/step - loss: 0.3982 - acc: 0.8839 - val_loss: 2.8296 - val_acc: 0.7301\n",
            "Epoch 5/300\n",
            "1154/1154 [==============================] - 12s 10ms/step - loss: 0.4869 - acc: 0.8769 - val_loss: 0.5439 - val_acc: 0.9031\n",
            "Epoch 6/300\n",
            "1154/1154 [==============================] - 12s 10ms/step - loss: 0.2580 - acc: 0.9350 - val_loss: 0.6291 - val_acc: 0.8893\n",
            "Epoch 7/300\n",
            "1154/1154 [==============================] - 11s 10ms/step - loss: 0.2761 - acc: 0.9263 - val_loss: 7.7175 - val_acc: 0.4567\n",
            "Epoch 8/300\n",
            "1154/1154 [==============================] - 11s 10ms/step - loss: 0.2006 - acc: 0.9515 - val_loss: 0.6030 - val_acc: 0.9100\n",
            "Epoch 9/300\n",
            "1154/1154 [==============================] - 11s 10ms/step - loss: 0.1907 - acc: 0.9541 - val_loss: 1.7648 - val_acc: 0.7751\n",
            "Epoch 10/300\n",
            "1154/1154 [==============================] - 11s 10ms/step - loss: 0.2591 - acc: 0.9307 - val_loss: 1.2127 - val_acc: 0.8581\n",
            "Epoch 11/300\n",
            "1154/1154 [==============================] - 12s 10ms/step - loss: 0.2472 - acc: 0.9385 - val_loss: 0.7529 - val_acc: 0.8927\n",
            "Epoch 12/300\n",
            "1154/1154 [==============================] - 11s 10ms/step - loss: 0.1761 - acc: 0.9610 - val_loss: 0.4790 - val_acc: 0.9377\n",
            "Epoch 13/300\n",
            "1154/1154 [==============================] - 12s 10ms/step - loss: 0.1666 - acc: 0.9558 - val_loss: 0.3012 - val_acc: 0.9619\n",
            "Epoch 14/300\n",
            "1154/1154 [==============================] - 11s 10ms/step - loss: 0.0928 - acc: 0.9740 - val_loss: 2.4692 - val_acc: 0.5017\n",
            "Epoch 15/300\n",
            "1154/1154 [==============================] - 11s 9ms/step - loss: 0.7518 - acc: 0.8154 - val_loss: 14.3334 - val_acc: 0.1107\n",
            "Epoch 16/300\n",
            "1154/1154 [==============================] - 11s 10ms/step - loss: 0.2879 - acc: 0.9281 - val_loss: 2.2196 - val_acc: 0.6574\n",
            "Epoch 17/300\n",
            "1154/1154 [==============================] - 11s 9ms/step - loss: 0.1268 - acc: 0.9740 - val_loss: 0.4932 - val_acc: 0.8927\n",
            "Epoch 18/300\n",
            "1154/1154 [==============================] - 11s 9ms/step - loss: 0.2070 - acc: 0.9558 - val_loss: 0.2297 - val_acc: 0.9585\n",
            "Epoch 19/300\n",
            "1154/1154 [==============================] - 11s 10ms/step - loss: 0.1835 - acc: 0.9558 - val_loss: 0.5691 - val_acc: 0.8858\n",
            "Epoch 20/300\n",
            "1154/1154 [==============================] - 11s 10ms/step - loss: 0.1813 - acc: 0.9593 - val_loss: 1.2827 - val_acc: 0.8201\n",
            "Epoch 21/300\n",
            "1154/1154 [==============================] - 11s 9ms/step - loss: 0.1127 - acc: 0.9714 - val_loss: 0.2067 - val_acc: 0.9758\n",
            "Epoch 22/300\n",
            "1154/1154 [==============================] - 12s 10ms/step - loss: 0.0903 - acc: 0.9731 - val_loss: 0.2494 - val_acc: 0.9516\n",
            "Epoch 23/300\n",
            "1154/1154 [==============================] - 11s 9ms/step - loss: 0.0909 - acc: 0.9792 - val_loss: 0.3083 - val_acc: 0.9585\n",
            "Epoch 24/300\n",
            "1154/1154 [==============================] - 11s 9ms/step - loss: 0.0820 - acc: 0.9809 - val_loss: 0.8425 - val_acc: 0.8339\n",
            "Epoch 25/300\n",
            "1154/1154 [==============================] - 11s 9ms/step - loss: 0.1472 - acc: 0.9645 - val_loss: 0.2499 - val_acc: 0.9689\n",
            "Epoch 26/300\n",
            "1154/1154 [==============================] - 11s 9ms/step - loss: 0.0708 - acc: 0.9818 - val_loss: 0.1211 - val_acc: 0.9896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-1c8abfbe9aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearlystop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcallback_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1Syh_gf96mKl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model evaluation: [loss, accuracy]"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DOsMu2xcMxNk",
        "outputId": "7cd076e9-0280-449d-8869-a709c85df02d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "619/619 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.030355545136540065, 0.9919224555735057]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "kRTWu7zW6DPm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(src+'final_mode.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SkbTn-K26uL4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classficiation report and confusion matrix"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kxeCoVGleYUw",
        "outputId": "dbfaee72-5f1b-43dd-d75e-424cde924117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions=np.argmax(predictions,axis=1)\n",
        "predictions.shape\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(619,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gRxNY_VcfTsk",
        "outputId": "15ab94b4-37b3-4639-c4cc-64f41e787164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.argmax(y_test,axis=1).shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(619,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-veZCJNgcE53",
        "outputId": "b13dade6-b24f-49f4-90ef-6992dd276bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "accuracy = accuracy_score(np.argmax(y_test,axis=1), predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print (classification_report(np.argmax(y_test,axis=1),predictions))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.19%\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       1.00      0.97      0.98        60\n",
            "          1       0.99      1.00      0.99        72\n",
            "          2       0.99      0.99      0.99        68\n",
            "          3       1.00      1.00      1.00        55\n",
            "          4       1.00      0.98      0.99        57\n",
            "          5       0.98      1.00      0.99        63\n",
            "          6       0.97      1.00      0.99        69\n",
            "          7       1.00      1.00      1.00        57\n",
            "          8       1.00      0.98      0.99        64\n",
            "          9       1.00      1.00      1.00        54\n",
            "\n",
            "avg / total       0.99      0.99      0.99       619\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oYNZ52Cve94i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_names = [i for i in range (10)]\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=True,\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    print(cm)\n",
        "    print ('\\n\\n')\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    '''\n",
        "    labels = classes\n",
        "    #cm = confusion_matrix(y_test, pred, labels)\n",
        "    print(cm)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm)\n",
        "    plt.title('Confusion matrix of the classifier')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticklabels([''] + labels)\n",
        "    ax.set_yticklabels([''] + labels)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "    '''\n",
        " \n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rf8-npMWjDDz",
        "outputId": "69eaf753-528c-4df0-91d0-b12028afe25e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "cnf_matrix = confusion_matrix(np.argmax(y_test,axis=1), predictions)\n",
        "\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[58  0  0  0  0  0  2  0  0  0]\n",
            " [ 0 72  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 67  0  0  1  0  0  0  0]\n",
            " [ 0  0  0 55  0  0  0  0  0  0]\n",
            " [ 0  1  0  0 56  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 63  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 69  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 57  0  0]\n",
            " [ 0  0  1  0  0  0  0  0 63  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 54]]\n",
            "\n",
            "\n",
            "\n",
            "Normalized confusion matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAGOCAYAAAANaaMoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wA0rJGAfZhcaAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f967fd9d860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I0Fw8_zuja3G",
        "outputId": "2f36555f-f9bc-4c4e-9ab9-9d741c1315de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "print (classification_report(np.argmax(y_test,axis=1),predictions))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       1.00      0.97      0.98        60\n",
            "          1       0.99      1.00      0.99        72\n",
            "          2       0.99      0.99      0.99        68\n",
            "          3       1.00      1.00      1.00        55\n",
            "          4       1.00      0.98      0.99        57\n",
            "          5       0.98      1.00      0.99        63\n",
            "          6       0.97      1.00      0.99        69\n",
            "          7       1.00      1.00      1.00        57\n",
            "          8       1.00      0.98      0.99        64\n",
            "          9       1.00      1.00      1.00        54\n",
            "\n",
            "avg / total       0.99      0.99      0.99       619\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7Ny534kikfWZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}